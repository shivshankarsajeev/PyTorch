During training, we use backpropagation to compute the gradient of the loss with respect to the weights.
This tells us how to adjust the weights to reduce the loss.
After computing the gradients using .backward(), we update the weights using gradient descent (weights -= learning_rate * weights.grad),
but we do this inside a with torch.no_grad() block to avoid tracking these operations in the computation graph.
After updating the weights, we reset their gradients to zero using .grad.zero_() so that the next backward pass starts fresh 
and does not accumulate gradients from previous iterations. This process repeats for each epoch
----------------------------------------------------------------------------------------------------------------------------------------

# üîπ Simple Example to Understand Backpropagation and torch.no_grad()

import torch

# Input and target
x = torch.tensor([2.0])
y_target = torch.tensor([4.0])

# Weight (requires gradient tracking)
w = torch.tensor([1.0], requires_grad=True)

# üî∏ 1. Forward pass
y_pred = w * x  # y_pred = 1.0 * 2.0 = 2.0

# üî∏ 2. Compute loss (Mean Squared Error)
loss = (y_pred - y_target) ** 2  # (2 - 4)^2 = 4.0

# üî∏ 3. Backward pass (compute gradient)
loss.backward()

# Print the gradient
print(f"Gradient before update: {w.grad.item()}")  # Should be -8.0

# üî∏ 4. Update weights using gradient descent (with no_grad)
learning_rate = 0.1
with torch.no_grad():
    w -= learning_rate * w.grad

# Print updated weight
print(f"Updated weight: {w.item()}")

# üî∏ 5. Zero the gradients
w.grad.zero_()

# Print gradient after zeroing
print(f"Gradient after zeroing: {w.grad.item()}")


‚ùì Why Do We Need with torch.no_grad()?
Here‚Äôs the key point:

PyTorch automatically tracks every operation you do on a tensor that has requires_grad=True ‚Äî this is called building a computation graph.

If you do:

w = w - 0.1 * w.grad
without torch.no_grad(), PyTorch thinks this is a new operation in the graph and will try to track it for gradients in the next backward pass.

üî• What Can Go Wrong Without torch.no_grad()?
Let‚Äôs say you forget torch.no_grad() and do:


w = w - 0.1 * w.grad  # no torch.no_grad()
Then on the next loss.backward() call:
  - PyTorch will try to calculate gradients through the weight update operation itself, which is not what we want.
  - It will throw errors like: RuntimeError: Trying to backward through the graph a second time...
  - Or worse: It will silently compute wrong gradients or use up too much memory by storing unnecessary history.

Use with torch.no_grad() whenever you're manually updating model parameters, so that PyTorch doesn't try to track those updates as part of the training computation graph. 
This keeps memory usage low and ensures gradients are calculated correctly for the next pass.
